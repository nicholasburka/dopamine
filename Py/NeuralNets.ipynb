{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Usage example employing Lasagne for digit recognition using the MNIST dataset.\n",
    "This example is deliberately structured as a long flat file, focusing on how\n",
    "to use Lasagne, instead of focusing on writing maximally modular and reusable\n",
    "code. It is used as the foundation for the introductory Lasagne tutorial:\n",
    "http://lasagne.readthedocs.org/en/latest/user/tutorial.html\n",
    "More in-depth examples and reproductions of paper results are maintained in\n",
    "a separate repository: https://github.com/Lasagne/Recipes\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "from theano import pp, printing\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ################## Download and prepare the MNIST dataset ##################\n",
    "# This is just some way of getting the MNIST dataset from an online location\n",
    "# and loading it into numpy arrays. It doesn't involve Lasagne at all.\n",
    "\n",
    "def load_dataset():\n",
    "    # We first define a download function, supporting both Python 2 and 3.\n",
    "    if sys.version_info[0] == 2:\n",
    "        from urllib import urlretrieve\n",
    "    else:\n",
    "        from urllib.request import urlretrieve\n",
    "\n",
    "    def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "        print(\"Downloading %s\" % filename)\n",
    "        urlretrieve(source + filename, filename)\n",
    "\n",
    "    # We then define functions for loading MNIST images and labels.\n",
    "    # For convenience, they also download the requested files if needed.\n",
    "    import gzip\n",
    "\n",
    "    def load_mnist_images(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        # Read the inputs in Yann LeCun's binary format.\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        # The inputs are vectors now, we reshape them to monochrome 2D images,\n",
    "        # following the shape convention: (examples, channels, rows, columns)\n",
    "        data = data.reshape(-1, 1, 28, 28)\n",
    "        # The inputs come as bytes, we convert them to float32 in range [0,1].\n",
    "        # (Actually to range [0, 255/256], for compatibility to the version\n",
    "        # provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)\n",
    "        return data / np.float32(256)\n",
    "\n",
    "    def load_mnist_labels(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        # Read the labels in Yann LeCun's binary format.\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        # The labels are vectors of integers now, that's exactly what we want.\n",
    "        return data\n",
    "\n",
    "    # We can now download and read the training and test set images and labels.\n",
    "    X_train = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "    y_train = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "    X_test = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "    y_test = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    # We reserve the last 10000 training examples for validation.\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "    # We just return all the arrays in order, as expected in main().\n",
    "    # (It doesn't matter how we do this as long as we can read them again.)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# ##################### Build the neural network model #######################\n",
    "# This script supports three types of models. For each one, we define a\n",
    "# function that takes a Theano variable representing the input and returns\n",
    "# the output layer of a neural network model built in Lasagne.\n",
    "\n",
    "def build_mlp(input_var=None):\n",
    "    # This creates an MLP of two hidden layers of 800 units each, followed by\n",
    "    # a softmax output layer of 10 units. It applies 20% dropout to the input\n",
    "    # data and 50% dropout to the hidden layers.\n",
    "\n",
    "    # Input layer, specifying the expected input shape of the network\n",
    "    # (unspecified batchsize, 1 channel, 28 rows and 28 columns) and\n",
    "    # linking it to the given Theano variable `input_var`, if any:\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, 28, 28),\n",
    "                                     input_var=input_var)\n",
    "\n",
    "    # Apply 20% dropout to the input data:\n",
    "    l_in_drop = lasagne.layers.DropoutLayer(l_in, p=0.2)\n",
    "\n",
    "    # Add a fully-connected layer of 800 units, using the linear rectifier, and\n",
    "    # initializing weights with Glorot's scheme (which is the default anyway):\n",
    "    l_hid1 = lasagne.layers.DenseLayer(\n",
    "            l_in_drop, num_units=800,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "\n",
    "    # We'll now add dropout of 50%:\n",
    "    #l_hid1_drop = lasagne.layers.DropoutLayer(l_hid1, p=0.5)\n",
    "\n",
    "    # Another 800-unit layer:\n",
    "    #l_hid2 = lasagne.layers.DenseLayer(\n",
    "    #        l_hid1_drop, num_units=800,\n",
    "    #        nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    # 50% dropout again:\n",
    "    #l_hid2_drop = lasagne.layers.DropoutLayer(l_hid2, p=0.5)\n",
    "\n",
    "    # Finally, we'll add the fully-connected output layer, of 10 softmax units:\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "            l_hid1, num_units=10,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    # Each layer is linked to its incoming layer(s), so we only need to pass\n",
    "    # the output layer to give access to a network in Lasagne:\n",
    "    return l_out\n",
    "\n",
    "\n",
    "def build_custom_mlp(input_var=None, depth=2, width=800, drop_input=.2,\n",
    "                     drop_hidden=.5):\n",
    "    # By default, this creates the same network as `build_mlp`, but it can be\n",
    "    # customized with respect to the number and size of hidden layers. This\n",
    "    # mostly showcases how creating a network in Python code can be a lot more\n",
    "    # flexible than a configuration file. Note that to make the code easier,\n",
    "    # all the layers are just called `network` -- there is no need to give them\n",
    "    # different names if all we return is the last one we created anyway; we\n",
    "    # just used different names above for clarity.\n",
    "\n",
    "    # Input layer and dropout (with shortcut `dropout` for `DropoutLayer`):\n",
    "    network = lasagne.layers.InputLayer(shape=(None, 1, 28, 28),\n",
    "                                        input_var=input_var)\n",
    "    if drop_input:\n",
    "        network = lasagne.layers.dropout(network, p=drop_input)\n",
    "    # Hidden layers and dropout:\n",
    "    nonlin = lasagne.nonlinearities.rectify\n",
    "    for _ in range(depth):\n",
    "        network = lasagne.layers.DenseLayer(\n",
    "                network, width, nonlinearity=nonlin)\n",
    "        if drop_hidden:\n",
    "            network = lasagne.layers.dropout(network, p=drop_hidden)\n",
    "    # Output layer:\n",
    "    softmax = lasagne.nonlinearities.softmax\n",
    "    network = lasagne.layers.DenseLayer(network, 10, nonlinearity=softmax)\n",
    "    return network\n",
    "\n",
    "\n",
    "def build_cnn(input_var=None):\n",
    "    # As a third model, we'll create a CNN of two convolution + pooling stages\n",
    "    # and a fully-connected hidden layer in front of the output layer.\n",
    "\n",
    "    # Input layer, as usual:\n",
    "    network = lasagne.layers.InputLayer(shape=(None, 1, 28, 28),\n",
    "                                        input_var=input_var)\n",
    "    # This time we do not apply input dropout, as it tends to work less well\n",
    "    # for convolutional layers.\n",
    "\n",
    "    # Convolutional layer with 32 kernels of size 5x5. Strided and padded\n",
    "    # convolutions are supported as well; see the docstring.\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=32, filter_size=(5, 5),\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "    # Expert note: Lasagne provides alternative convolutional layers that\n",
    "    # override Theano's choice of which implementation to use; for details\n",
    "    # please see http://lasagne.readthedocs.org/en/latest/user/tutorial.html.\n",
    "\n",
    "    # Max-pooling layer of factor 2 in both dimensions:\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # Another convolution with 32 5x5 kernels, and another 2x2 pooling:\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=32, filter_size=(5, 5),\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # A fully-connected layer of 256 units with 50% dropout on its inputs:\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=256,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    # And, finally, the 10-unit output layer with 50% dropout on its inputs:\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=10,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "# ############################# Batch iterator ###############################\n",
    "# This is just a simple helper function iterating over training data in\n",
    "# mini-batches of a particular size, optionally in random order. It assumes\n",
    "# data is available as numpy arrays. For big datasets, you could load numpy\n",
    "# arrays as memory-mapped files (np.load(..., mmap_mode='r')), or write your\n",
    "# own custom data iteration function. For small datasets, you can also copy\n",
    "# them to GPU at once for slightly improved performance. This would involve\n",
    "# several changes in the main program, though, and is not demonstrated here.\n",
    "# Notice that this function returns only mini-batches of size `batchsize`.\n",
    "# If the size of the data is not a multiple of `batchsize`, it will not\n",
    "# return the last (remaining) mini-batch.\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 10 took 6.301s\n",
      "  training loss:\t\t0.908627\n",
      "  validation loss:\t\t0.398168\n",
      "  validation accuracy:\t\t89.64 %\n",
      "Epoch 2 of 10 took 6.946s\n",
      "  training loss:\t\t0.430776\n",
      "  validation loss:\t\t0.322637\n",
      "  validation accuracy:\t\t91.21 %\n",
      "Epoch 3 of 10 took 8.231s\n",
      "  training loss:\t\t0.372223\n",
      "  validation loss:\t\t0.290894\n",
      "  validation accuracy:\t\t91.86 %\n",
      "Epoch 4 of 10 took 7.801s\n",
      "  training loss:\t\t0.341401\n",
      "  validation loss:\t\t0.267018\n",
      "  validation accuracy:\t\t92.58 %\n",
      "Epoch 5 of 10 took 7.664s\n",
      "  training loss:\t\t0.319395\n",
      "  validation loss:\t\t0.250520\n",
      "  validation accuracy:\t\t93.08 %\n",
      "Epoch 6 of 10 took 6.967s\n",
      "  training loss:\t\t0.302520\n",
      "  validation loss:\t\t0.236531\n",
      "  validation accuracy:\t\t93.29 %\n",
      "Epoch 7 of 10 took 6.825s\n",
      "  training loss:\t\t0.284693\n",
      "  validation loss:\t\t0.225285\n",
      "  validation accuracy:\t\t93.69 %\n",
      "Epoch 8 of 10 took 6.690s\n",
      "  training loss:\t\t0.271732\n",
      "  validation loss:\t\t0.213707\n",
      "  validation accuracy:\t\t94.15 %\n",
      "Epoch 9 of 10 took 6.864s\n",
      "  training loss:\t\t0.260850\n",
      "  validation loss:\t\t0.203416\n",
      "  validation accuracy:\t\t94.53 %\n",
      "Epoch 10 of 10 took 6.785s\n",
      "  training loss:\t\t0.248486\n",
      "  validation loss:\t\t0.197605\n",
      "  validation accuracy:\t\t94.68 %\n",
      "Final results:\n",
      "  test loss:\t\t\t0.204068\n",
      "  test accuracy:\t\t94.23 %\n"
     ]
    }
   ],
   "source": [
    "# ############################## Main program ################################\n",
    "# Everything else will be handled in our main program now. We could pull out\n",
    "# more functions to better separate the code, but it wouldn't make it any\n",
    "# easier to read.\n",
    "\n",
    "def main(model='mlp', num_epochs=500):\n",
    "    # Load the dataset\n",
    "    print(\"Loading data...\")\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "\n",
    "    # Prepare Theano variables for inputs and targets\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    # Create neural network model (depending on first command line parameter)\n",
    "    print(\"Building model and compiling functions...\")\n",
    "    if model == 'mlp':\n",
    "        network = build_mlp(input_var)\n",
    "    elif model.startswith('custom_mlp:'):\n",
    "        depth, width, drop_in, drop_hid = model.split(':', 1)[1].split(',')\n",
    "        network = build_custom_mlp(input_var, int(depth), int(width),\n",
    "                                   float(drop_in), float(drop_hid))\n",
    "    elif model == 'cnn':\n",
    "        network = build_cnn(input_var)\n",
    "    else:\n",
    "        print(\"Unrecognized model type %r.\" % model)\n",
    "        return\n",
    "\n",
    "    # Create a loss expression for training, i.e., a scalar objective we want\n",
    "    # to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    # We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "    # Create update expressions for training, i.e., how to modify the\n",
    "    # parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "    # Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    updates = lasagne.updates.nesterov_momentum(\n",
    "            loss, params, learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    # Create a loss expression for validation/testing. The crucial difference\n",
    "    # here is that we do a deterministic forward pass through the network,\n",
    "    # disabling dropout layers.\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                            target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "    # As a bonus, also create an expression for the classification accuracy:\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                      dtype=theano.config.floatX)\n",
    "\n",
    "    # Compile a function performing a training step on a mini-batch (by giving\n",
    "    # the updates dictionary) and returning the corresponding training loss:\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "    # Compile a second function computing the validation loss and accuracy:\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "\n",
    "    # Finally, launch the training loop.\n",
    "    print(\"Starting training...\")\n",
    "    # We iterate over epochs:\n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for batch in iterate_minibatches(X_train, y_train, 500, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_val, y_val, 500, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "            val_acc / val_batches * 100))\n",
    "\n",
    "    # After training, we compute and print the test error:\n",
    "    test_err = 0\n",
    "    test_acc = 0\n",
    "    test_batches = 0\n",
    "    for batch in iterate_minibatches(X_test, y_test, 500, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        test_err += err\n",
    "        test_acc += acc\n",
    "        test_batches += 1\n",
    "    print(\"Final results:\")\n",
    "    print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "    print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "        test_acc / test_batches * 100))\n",
    "\n",
    "\n",
    "\n",
    "    # Optionally, you could now dump the network weights to a file like this:\n",
    "    # np.savez('model.npz', *lasagne.layers.get_all_param_values(network))\n",
    "    #\n",
    "    # And load them again later on like this:\n",
    "    # with np.load('model.npz') as f:\n",
    "    #     param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    # lasagne.layers.set_all_param_values(network, param_values)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if ('--help' in sys.argv) or ('-h' in sys.argv):\n",
    "        print(\"Trains a neural network on MNIST using Lasagne.\")\n",
    "        print(\"Usage: %s [MODEL [EPOCHS]]\" % sys.argv[0])\n",
    "        print()\n",
    "        print(\"MODEL: 'mlp' for a simple Multi-Layer Perceptron (MLP),\")\n",
    "        print(\"       'custom_mlp:DEPTH,WIDTH,DROP_IN,DROP_HID' for an MLP\")\n",
    "        print(\"       with DEPTH hidden layers of WIDTH units, DROP_IN\")\n",
    "        print(\"       input dropout and DROP_HID hidden dropout,\")\n",
    "        print(\"       'cnn' for a simple Convolutional Neural Network (CNN).\")\n",
    "        print(\"EPOCHS: number of training epochs to perform (default: 500)\")\n",
    "    else:\n",
    "        kwargs = {}\n",
    "        #print (str(sys.argv))\n",
    "        #if len(sys.argv) > 1:\n",
    "        #    kwargs['model'] = sys.argv[1]\n",
    "        #if len(sys.argv) > 2:\n",
    "        #    kwargs['num_epochs'] = int(sys.argv[2])\n",
    "main('mlp', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing.debugprint(lasagne.utils.one_hot([1,2,3], m=None))\n",
    "#lasagne.layers.get_output(lasagne.utils.one_hot([1,2,3], m=15), deterministic=True)\n",
    "num_inp = 1000\n",
    "t = np.zeros((num_inp,1,1,15))\n",
    "for i in range(num_inp):\n",
    "    t[i,0,0,np.random.randint(0,15)] = 1\n",
    "    \n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Analysis Helper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compile_saliency_function(net,inpu):\n",
    "    \"\"\"\n",
    "    Compiles a function to compute the saliency maps and predicted classes\n",
    "    for a given minibatch of input images.\n",
    "    \"\"\"\n",
    "    inp = inpu\n",
    "    outp = lasagne.layers.get_output(net, deterministic=True)\n",
    "    max_outp = T.max(outp, axis=1)\n",
    "    saliency = theano.grad(max_outp.sum(), wrt=inp)\n",
    "    max_class = T.argmax(outp, axis=1)\n",
    "    return theano.function([inp], [saliency, max_class])\n",
    "\n",
    "\n",
    "\n",
    "def show_images(img_original, saliency, max_class, title):\n",
    "    # get out the first map and class from the mini-batch\n",
    "    #saliency = saliency[0]\n",
    "    #max_class = max_class[0]\n",
    "    # convert saliency from BGR to RGB, and from c01 to 01c\n",
    "    #saliency = saliency[::-1].transpose(1, 2, 0)\n",
    "    # plot the original image and the three saliency map variants\n",
    "    plt.figure(figsize=(1, 15), facecolor='w')\n",
    "    #plt.suptitle(\"Class: \" + max_class + \". Saliency: \" + title)\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.title('input')\n",
    "    plt.imshow(img_original)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.title('abs. saliency')\n",
    "    plt.imshow(np.abs(saliency), cmap='gray')\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.title('pos. saliency')\n",
    "    plt.imshow((np.maximum(0, saliency) / saliency.max()))\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.title('neg. saliency')\n",
    "    plt.imshow((np.maximum(0, -saliency) / -saliency.min()))\n",
    "    plt.show()\n",
    "    \n",
    "def _blob(x, y, area, colour):\n",
    "    \"\"\"\n",
    "    Draws a square-shaped blob with the given area (< 1) at\n",
    "    the given coordinates.\n",
    "    \"\"\"\n",
    "    hs = np.sqrt(area) / 2\n",
    "    xcorners = np.array([x - hs, x + hs, x + hs, x - hs])\n",
    "    ycorners = np.array([y - hs, y - hs, y + hs, y + hs])\n",
    "    plt.fill(xcorners, ycorners, colour, edgecolor=colour)\n",
    "\n",
    "def hinton(W, names=None, maxweight=None, filename=None):\n",
    "# def hinton(W, maxweight=None):\n",
    "    \"\"\"\n",
    "    Draws a Hinton diagram for visualizing a weight matrix. \n",
    "    Temporarily disables matplotlib interactive mode if it is on, \n",
    "    otherwise this takes forever.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # F = plt.gcf()\n",
    "    # F.set_dpi( 300 )\n",
    "    # print \"DPI\", F.get_dpi()\n",
    "\n",
    "    F = plt.figure(num=None, figsize=(8,6), dpi=300, facecolor='w', edgecolor='k')\n",
    "\n",
    "    reenable = False\n",
    "    if plt.isinteractive():\n",
    "        plt.ioff()\n",
    "    \n",
    "    F.clf()\n",
    "    height, width = W.shape\n",
    "    if not maxweight:\n",
    "        maxweight = 2**np.ceil(np.log(np.max(np.abs(W)))/np.log(2))\n",
    "        print (\"Max weight: \"  + str(maxweight))\n",
    "        \n",
    "    plt.fill(np.array([0, width, width, 0]),\n",
    "             np.array([0, 0, height, height]),\n",
    "             'gray')\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.axis('equal')\n",
    "    for x in xrange(width):\n",
    "        if names:\n",
    "            plt.text(-0.5, x, names[x], fontsize=4, ha='right', va='bottom')\n",
    "            plt.text(x, height+0.5, names[height-x-1], fontsize=4, va='bottom', rotation='vertical', ha='left')\n",
    "        for y in xrange(height):\n",
    "            _x = x+1\n",
    "            _y = y+1\n",
    "            w = W[y, x]\n",
    "            if w > 0:\n",
    "                _blob(_x - 0.5,\n",
    "                      height - _y + 0.5,\n",
    "                      min(1, w/maxweight),\n",
    "                      'white')\n",
    "            elif w < 0:\n",
    "                _blob(_x - 0.5,\n",
    "                      height - _y + 0.5, \n",
    "                      min(1, -w/maxweight), \n",
    "                      'black')\n",
    "    if reenable:\n",
    "        plt.ion()\n",
    "\n",
    "    if filename:\n",
    "        F.savefig(filename, dpi=300)\n",
    "        #print >>sys.stderr, \"Wrote:\", filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data and Neural Network Definitions\n",
    "===================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_dataset(num_inp=10000, num_test=2000, num_categories=15, timesteps_per_stim=4):\n",
    "    num_inp = 1000\n",
    "    X_train = np.zeros((num_inp*timesteps_per_stim,1,1,num_categories))\n",
    "    y_train = np.zeros((num_inp*timesteps_per_stim))\n",
    "    \n",
    "    for i in range(num_inp):\n",
    "        r = np.random.randint(0,num_categories)\n",
    "        for j in range(timesteps_per_stim):\n",
    "            X_train[i*timesteps_per_stim+j,0,0,r] = 1\n",
    "            y_train[i*timesteps_per_stim+j] = (1.0/(num_categories-1))*r\n",
    "    \n",
    "    # We reserve the last training examples for validation.\n",
    "    X_train, X_val = X_train[:-(num_inp/10)], X_train[-(num_inp/10):]\n",
    "    y_train, y_val = y_train[:-(num_inp/10)], y_train[-(num_inp/10):]\n",
    "    \n",
    "    \n",
    "    X_test = np.zeros((num_test*timesteps_per_stim,1,1,num_categories))\n",
    "    y_test = np.zeros((num_test*timesteps_per_stim))\n",
    "    for i in range(num_test):\n",
    "        r = np.random.randint(0,num_categories)\n",
    "        for j in range(timesteps_per_stim):\n",
    "            X_test[i*timesteps_per_stim+j,0,0,r] = 1\n",
    "            y_test[i*timesteps_per_stim+j] = (1.0/(num_categories-1))*r\n",
    "        \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "def feed_forward(input_var, num_categories, dropout=False, num_hid=100):\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, 1, num_categories), input_var=input_var)\n",
    "    \n",
    "    if (dropout):\n",
    "        l_in_drop = lasagne.layers.DropoutLayer(l_in, p=0.2)\n",
    "    \n",
    "        l_hid1 = lasagne.layers.DenseLayer(\n",
    "                l_in_drop, num_units=num_hid,\n",
    "                nonlinearity=lasagne.nonlinearities.rectify,\n",
    "                W=lasagne.init.GlorotUniform())\n",
    "    else:\n",
    "        l_hid1 = lasagne.layers.DenseLayer(\n",
    "                l_in, num_units=num_hid,\n",
    "                nonlinearity=lasagne.nonlinearities.rectify,\n",
    "                W=lasagne.init.GlorotUniform())\n",
    "    \n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "            l_hid1, num_units=1,\n",
    "            nonlinearity=lasagne.nonlinearities.sigmoid)\n",
    "    \n",
    "    return l_out\n",
    "    \n",
    "def recursive(rec_input_var, num_categories, gru=True):\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, 1, num_categories), input_var=rec_input_var)\n",
    "    \n",
    "    #l_in_drop = lasagne.layers.DropoutLayer(l_in, p=0.2)\n",
    "    \n",
    "    if (gru):\n",
    "        l_rec = lasagne.layers.GRULayer(l_in, num_units=100)\n",
    "    else:\n",
    "        l_rec = lasagne.layers.LSTMLayer(l_in, num_units=100)\n",
    "\n",
    "    l_shp = lasagne.layers.ReshapeLayer(l_rec, (-1, 100))\n",
    "    \n",
    "    l_hid1 = lasagne.layers.DenseLayer(\n",
    "            l_shp, num_units=100,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "    \n",
    "    \n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "            l_hid1, num_units=1,\n",
    "            nonlinearity=lasagne.nonlinearities.sigmoid)\n",
    "    \n",
    "    return l_out\n",
    "\n",
    "def in_out(input_var, num_categories, recursive_layer=False):\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, 1, num_categories), input_var=input_var)\n",
    "    \n",
    "    if (not recursive_layer):\n",
    "        l_in_drop = lasagne.layers.DropoutLayer(l_in, p=0.2)\n",
    "        \n",
    "        l_hid1 = lasagne.layers.DenseLayer(\n",
    "                l_in_drop, num_units=100,\n",
    "                nonlinearity=lasagne.nonlinearities.rectify,\n",
    "                W=lasagne.init.GlorotUniform())\n",
    "    \n",
    "    else:\n",
    "        l_lstm = lasagne.layers.LSTMLayer(l_in, num_units=100)\n",
    "\n",
    "        l_shp = lasagne.layers.ReshapeLayer(l_lstm, (-1, 100))\n",
    "    \n",
    "        l_hid1 = lasagne.layers.DenseLayer(\n",
    "                l_shp, num_units=100,\n",
    "                nonlinearity=lasagne.nonlinearities.rectify,\n",
    "                W=lasagne.init.GlorotUniform())\n",
    "        \n",
    "    l_flat_in = lasagne.layers.FlattenLayer(l_in, outdim=1)\n",
    "    l_flat_h = lasagne.layers.FlattenLayer(l_hid1, outdim=1)\n",
    "    \n",
    "    l_merge = lasagne.layers.ConcatLayer((l_flat_in, l_flat_h), axis=0)\n",
    "    \n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "            l_merge, num_units=1,\n",
    "            nonlinearity=lasagne.nonlinearities.sigmoid)\n",
    "    \n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_rec(print_epoch=False, num_inp=10000, num_test=2000, num_categories=15, timesteps_per_stim=4, num_epochs=100):\n",
    "    num_categories = 15\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = load_dataset(num_categories=15, timesteps_per_stim=timesteps_per_stim)\n",
    "\n",
    "    rec_input_var = T.tensor4('inputs')\n",
    "    rec_target_var = T.dvector('targets')\n",
    "\n",
    "    rec_network = recursive(rec_input_var, num_categories)\n",
    "\n",
    "    # Create a loss expression for training, i.e., a scalar objective we want\n",
    "    # to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "    rec_prediction = lasagne.layers.get_output(rec_network)\n",
    "    rec_loss = lasagne.objectives.squared_error(rec_prediction, rec_target_var)\n",
    "    rec_loss = rec_loss.mean()\n",
    "    # We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "    # Create update expressions for training, i.e., how to modify the\n",
    "    # parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "    # Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "    rec_params = lasagne.layers.get_all_params(rec_network, trainable=True)\n",
    "    rec_updates = lasagne.updates.nesterov_momentum(\n",
    "        rec_loss, rec_params, learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    # Create a loss expression for validation/testing. The crucial difference\n",
    "    # here is that we do a deterministic forward pass through the network,\n",
    "    # disabling dropout layers.\n",
    "    rec_test_prediction = lasagne.layers.get_output(rec_network, deterministic=True)\n",
    "    rec_test_loss = lasagne.objectives.squared_error(rec_test_prediction,\n",
    "                                                                rec_target_var)\n",
    "    rec_test_loss = rec_test_loss.mean()\n",
    "\n",
    "    # As a bonus, also create an expression for the classification accuracy:\n",
    "    #test_acc = T.mean((test_prediction - target_var),dtype=theano.config.floatX)\n",
    "\n",
    "    # Compile a function performing a training step on a mini-batch (by giving\n",
    "    # the updates dictionary) and returning the corresponding training loss:\n",
    "    rec_train_fn = theano.function([rec_input_var, rec_target_var], rec_loss, updates=rec_updates)\n",
    "\n",
    "    # Compile a second function computing the validation loss and accuracy:\n",
    "    rec_val_fn = theano.function([rec_input_var, rec_target_var], rec_test_loss)\n",
    "\n",
    "    # Finally, launch the training loop.\n",
    "    print(\"Starting training...\")\n",
    "    # We iterate over epochs:\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for batch in iterate_minibatches(X_train, y_train, 30, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_err += rec_train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_val, y_val, 30, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err = rec_val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_batches += 1\n",
    "            #val_acc += acc\n",
    "\n",
    "        if (print_epoch):\n",
    "            # Then we print the results for this epoch:\n",
    "            print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "                epoch + 1, num_epochs, time.time() - start_time))\n",
    "            print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "            print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "            #print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "            #    val_acc / val_batches * 100))\n",
    "\n",
    "    # After training, we compute and print the test error:\n",
    "    test_err = 0\n",
    "    test_acc = 0\n",
    "    test_batches = 0\n",
    "    for batch in iterate_minibatches(X_test, y_test, 30, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err = rec_val_fn(inputs, targets)\n",
    "        test_err += err\n",
    "        test_batches += 1\n",
    "        #test_acc += acc\n",
    "    print(\"Final results:\")\n",
    "    print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "    #print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    #    test_acc / test_batches * 100))\n",
    "    \n",
    "    return rec_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsaliency_fn = compile_saliency_function(ff_network, ff_input_var)\\nsaliency, max_class = saliency_fn(X_train[1].reshape(1,1,1,15))\\n#plt.subplot(2, 2, 1)\\n#plt.imshow(X_train[1].reshape(15,1))\\n#plt.subplot(2, 2, 2)\\n#plt.imshow(saliency.reshape(15,1))\\n#print (\\'saliency shape: \\' + str(saliency.shape))\\nshow_images(X_train[1].reshape(15,1), saliency.reshape(15,1), max_class, \"guided backprop\")\\n#hinton(l)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_ff(print_epoch=False, num_inp=10000, num_test=2000, num_categories=15, timesteps_per_stim=4, num_epochs=100):\n",
    "    num_categories = 15\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = load_dataset(num_categories=15, timesteps_per_stim=timesteps_per_stim)\n",
    "\n",
    "    ff_input_var = T.tensor4('inputs')\n",
    "    ff_target_var = T.dvector('targets')\n",
    "\n",
    "    ff_network = feed_forward(ff_input_var, num_categories)\n",
    "\n",
    "    # Create a loss expression for training, i.e., a scalar objective we want\n",
    "    # to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "    ff_prediction = lasagne.layers.get_output(ff_network)\n",
    "    ff_loss = lasagne.objectives.squared_error(ff_prediction, ff_target_var)\n",
    "    ff_loss = ff_loss.mean()\n",
    "    # We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "    # Create update expressions for training, i.e., how to modify the\n",
    "    # parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "    # Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "    ff_params = lasagne.layers.get_all_params(ff_network, trainable=True)\n",
    "    ff_updates = lasagne.updates.nesterov_momentum(\n",
    "        ff_loss, ff_params, learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    # Create a loss expression for validation/testing. The crucial difference\n",
    "    # here is that we do a deterministic forward pass through the network,\n",
    "    # disabling dropout layers.\n",
    "    ff_test_prediction = lasagne.layers.get_output(ff_network, deterministic=True)\n",
    "    ff_test_loss = lasagne.objectives.squared_error(ff_test_prediction,\n",
    "                                                                ff_target_var)\n",
    "    ff_test_loss = ff_test_loss.mean()\n",
    "\n",
    "    # As a bonus, also create an expression for the classification accuracy:\n",
    "    #test_acc = T.mean((test_prediction - target_var),dtype=theano.config.floatX)\n",
    "\n",
    "    # Compile a function performing a training step on a mini-batch (by giving\n",
    "    # the updates dictionary) and returning the corresponding training loss:\n",
    "    ff_train_fn = theano.function([ff_input_var, ff_target_var], ff_loss, updates=ff_updates)\n",
    "\n",
    "    # Compile a second function computing the validation loss and accuracy:\n",
    "    ff_val_fn = theano.function([ff_input_var, ff_target_var], ff_test_loss)\n",
    "\n",
    "    # Finally, launch the training loop.\n",
    "    print(\"Starting training...\")\n",
    "    # We iterate over epochs:\n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for batch in iterate_minibatches(X_train, y_train, 30, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_err += ff_train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_val, y_val, 30, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err = ff_val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_batches += 1\n",
    "            #val_acc += acc\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        if print_epoch:\n",
    "            print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "                epoch + 1, num_epochs, time.time() - start_time))\n",
    "            print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "            print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "            #print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "            #    val_acc / val_batches * 100))\n",
    "\n",
    "    # After training, we compute and print the test error:\n",
    "    test_err = 0\n",
    "    test_acc = 0\n",
    "    test_batches = 0\n",
    "    for batch in iterate_minibatches(X_test, y_test, 30, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err = ff_val_fn(inputs, targets)\n",
    "        test_err += err\n",
    "        test_batches += 1\n",
    "        #test_acc += acc\n",
    "    print(\"Final results:\")\n",
    "    print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "    #print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    #    test_acc / test_batches * 100))\n",
    "    return ff_network\n",
    "\n",
    "\n",
    "'''\n",
    "saliency_fn = compile_saliency_function(ff_network, ff_input_var)\n",
    "saliency, max_class = saliency_fn(X_train[1].reshape(1,1,1,15))\n",
    "#plt.subplot(2, 2, 1)\n",
    "#plt.imshow(X_train[1].reshape(15,1))\n",
    "#plt.subplot(2, 2, 2)\n",
    "#plt.imshow(saliency.reshape(15,1))\n",
    "#print ('saliency shape: ' + str(saliency.shape))\n",
    "show_images(X_train[1].reshape(15,1), saliency.reshape(15,1), max_class, \"guided backprop\")\n",
    "#hinton(l)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_categories = 15\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset(num_categories=15)\n",
    "\n",
    "input_var = T.tensor4('inputs')\n",
    "target_var = T.dvector('targets')\n",
    "\n",
    "network = in_out(input_var, num_categories)\n",
    "\n",
    "# Create a loss expression for training, i.e., a scalar objective we want\n",
    "# to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.squared_error(prediction, target_var)\n",
    "loss = loss.mean()\n",
    "# We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "# Create update expressions for training, i.e., how to modify the\n",
    "# parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "# Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(\n",
    "    loss, params, learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "# Create a loss expression for validation/testing. The crucial difference\n",
    "# here is that we do a deterministic forward pass through the network,\n",
    "# disabling dropout layers.\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.squared_error(test_prediction,\n",
    "                                                            target_var)\n",
    "test_loss = test_loss.mean()\n",
    "\n",
    "# As a bonus, also create an expression for the classification accuracy:\n",
    "#test_acc = T.mean((test_prediction - target_var),dtype=theano.config.floatX)\n",
    "\n",
    "# Compile a function performing a training step on a mini-batch (by giving\n",
    "# the updates dictionary) and returning the corresponding training loss:\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "# Compile a second function computing the validation loss and accuracy:\n",
    "val_fn = theano.function([input_var, target_var], test_loss)\n",
    "\n",
    "# Finally, launch the training loop.\n",
    "print(\"Starting training...\")\n",
    "# We iterate over epochs:\n",
    "num_epochs = 150\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train, 30, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, 30, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err = val_fn(inputs, targets)\n",
    "        val_err += err\n",
    "        val_batches += 1\n",
    "        #val_acc += acc\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    #print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "    #    val_acc / val_batches * 100))\n",
    "\n",
    "# After training, we compute and print the test error:\n",
    "test_err = 0\n",
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 30, shuffle=False):\n",
    "    inputs, targets = batch\n",
    "    err = val_fn(inputs, targets)\n",
    "    test_err += err\n",
    "    test_batches += 1\n",
    "    #test_acc += acc\n",
    "print(\"Final results:\")\n",
    "print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "#print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "#    test_acc / test_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 100)\n",
      "(100,)\n",
      "(100, 1)\n",
      "(1,)\n",
      "Max weight: 1.0\n",
      "Max weight: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArAAAAH4CAYAAACyp94qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGQ9dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e679210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqAAAAH/CAYAAACIDG96AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e0a3e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in lasagne.layers.get_all_param_values(ff_network):\n",
    "    print (i.shape)\n",
    "    \n",
    "W = lasagne.layers.get_all_param_values(ff_network)\n",
    "hinton(W[0])\n",
    "hinton(W[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Final results:\n",
      "  test loss:\t\t\t0.000597\n",
      "Starting training...\n",
      "Final results:\n",
      "  test loss:\t\t\t0.000025\n"
     ]
    }
   ],
   "source": [
    "per_stim = 5\n",
    "epochs = 10\n",
    "ff_network = train_ff(timesteps_per_stim=per_stim, num_epochs=epochs)\n",
    "rec_network = train_rec(timesteps_per_stim=per_stim, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.06565611]\n",
      " [ 0.09603352]\n",
      " [ 0.1479801 ]\n",
      " [ 0.2084768 ]\n",
      " [ 0.28515183]\n",
      " [ 0.35459191]\n",
      " [ 0.4272442 ]\n",
      " [ 0.50091357]\n",
      " [ 0.57243417]\n",
      " [ 0.64394368]\n",
      " [ 0.71692228]\n",
      " [ 0.78799108]\n",
      " [ 0.85685399]\n",
      " [ 0.90600397]\n",
      " [ 0.93729448]]\n",
      "[[ 0.01292153]\n",
      " [ 0.07056681]\n",
      " [ 0.14261756]\n",
      " [ 0.21418342]\n",
      " [ 0.28566907]\n",
      " [ 0.35707752]\n",
      " [ 0.42854105]\n",
      " [ 0.50002375]\n",
      " [ 0.57144942]\n",
      " [ 0.64294079]\n",
      " [ 0.71436133]\n",
      " [ 0.78582629]\n",
      " [ 0.85736775]\n",
      " [ 0.92930611]\n",
      " [ 0.9857071 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAC7CAYAAADv/w2vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBERkYwUEkRERCQjhQQRERHJ6P8DVgoRobmrw3wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1125e9b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAC7CAYAAADv/w2vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZW0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d46c0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_testo = np.zeros((15,1,1,15))\n",
    "y_testo = np.zeros((15))\n",
    "for i in range(15):\n",
    "        r = 15\n",
    "        X_testo[i,0,0,i] = 1\n",
    "        y_testo[i] = (1.0/(num_categories-1))*i\n",
    "\n",
    "\n",
    "input_theano_var = T.tensor4('inputs')\n",
    "ff_pred = lasagne.layers.get_output(ff_network, input_theano_var)\n",
    "get_ff_pred = theano.function([input_theano_var], ff_pred)\n",
    "#print(X_train[1].reshape((1,1,1,15)))\n",
    "print(get_ff_pred(X_testo))\n",
    "\n",
    "r_input_theano_var = T.tensor4('inputs')\n",
    "r_pred = lasagne.layers.get_output(rec_network, r_input_theano_var)\n",
    "get_r_pred = theano.function([r_input_theano_var], r_pred)\n",
    "#print(X_train[1].reshape((1,1,1,15)))\n",
    "print(get_r_pred(X_testo))\n",
    "#print(y_testo)\n",
    "\n",
    "\n",
    "\n",
    "test_res = get_ff_pred(X_testo).reshape(15)\n",
    "t1 = np.arange(len(test_res))\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.plot(t1, get_ff_pred(X_testo).reshape(15))\n",
    "plt.show()\n",
    "\n",
    "test_res = get_r_pred(X_testo).reshape(15)\n",
    "t1 = np.arange(len(test_res))\n",
    "plt.figure(1)\n",
    "plt.subplot(212)\n",
    "plt.plot(t1, get_r_pred(X_testo).reshape(15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex = np.zeros((1,1,1,15))\n",
    "ex[0,0,0,1] = 1\n",
    "input_var = ex\n",
    "\n",
    "lasagne.layers.get_output(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train[1].reshape(1,15)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
